{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "from degnna.nn.radial_basis import BesselBasis\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from degnna.model import SequentialGraphModel\n",
    "from degnna.nn._one_hot import OneHotAtomEncoding\n",
    "from degnna.nn._edge import RadialBasisEdgeEncoding, SphericalHarmonicEdgeAttrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 10.\n",
    "\n",
    "one_hot_module = OneHotAtomEncoding(\n",
    "    num_types= 22,\n",
    ")\n",
    "radial_basis_module = RadialBasisEdgeEncoding(\n",
    "    irreps_in=one_hot_module.irreps_out,\n",
    "    basis_kwargs= {'r_max': r_max, 'num_basis': 8},\n",
    "    cutoff_kwargs={'r_max': r_max},\n",
    ")\n",
    "spharm_module = SphericalHarmonicEdgeAttrs(\n",
    "    irreps_in=radial_basis_module.irreps_out,\n",
    "    irreps_edge_sh=2,\n",
    ")\n",
    "\n",
    "model = SequentialGraphModel(\n",
    "    modules={\n",
    "        'one_hot': one_hot_module,\n",
    "        'radial_basis': radial_basis_module,\n",
    "        'spharm': spharm_module,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from degnna.data.dataset import TrajDataset\n",
    "from degnna.data import DataLoader\n",
    "\n",
    "dataset = TrajDataset(\n",
    "        root='results',\n",
    "        dataset_idx=0,\n",
    "        structure_filename='/storage_common/angiod/A2A/tpr/a2a.tpr',\n",
    "        traj_filenames = ['/storage_common/angiod/A2A/trr/a2a.trr'],\n",
    "        selection = 'name CA',\n",
    "        extra_fixed_fields={'r_max': r_max}\n",
    "    )\n",
    "\n",
    "dl_kwargs = dict(\n",
    "    num_workers=1,\n",
    "    # keep stuff around in memory\n",
    "    persistent_workers=(\n",
    "        True\n",
    "    ),\n",
    "    # PyTorch recommends this for GPU since it makes copies much faster\n",
    "    # avoid getting stuck\n",
    "    # use the right randomness\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2,\n",
    "    **dl_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from degnna.data import AtomicData\n",
    "\n",
    "\n",
    "for batch in loader:\n",
    "    batch = AtomicData.to_AtomicDataDict(batch)\n",
    "    out = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['edge_index', 'pos', 'batch', 'ptr', 'edge_cell_shift', 'atom_types', 'pbc', 'dataset_idx', 'r_max', 'cell', 'node_attrs', 'node_features', 'edge_vectors', 'edge_lengths', 'edge_embedding', 'edge_attrs'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max = 10\n",
    "r_max = 10.\n",
    "num_basis = 8\n",
    "resolution = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = BesselBasis(r_max=r_max, num_basis=num_basis)\n",
    "weights = []\n",
    "for _ in range((L_max+1)**2):\n",
    "    weights.append(torch.randn((num_basis,)))\n",
    "weights = torch.stack(weights, dim=0) # (num_spharm, num_basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x: float, weights: torch.Tensor, basis: BesselBasis):\n",
    "    with torch.no_grad():\n",
    "        y = basis(x)\n",
    "    return torch.einsum('i,i->', y, weights)\n",
    "\n",
    "def sample_range(x: torch.Tensor, weights: torch.Tensor, basis: BesselBasis):\n",
    "    with torch.no_grad():\n",
    "        y = basis(x)\n",
    "    return torch.einsum('ji,i->j', y, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in weights:\n",
    "    plt.plot(sample_range(torch.linspace(0, 10, 1000), w, basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import e3nn\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, beta = torch.meshgrid(\n",
    "#     torch.linspace(0.0, 2 * torch.pi, 30),\n",
    "#     torch.linspace(0.0, torch.pi, 30),\n",
    "#     indexing=\"ij\"\n",
    "# )\n",
    "\n",
    "# vectors = e3nn.o3.angles_to_xyz(alpha, beta)  # Vectors on the surface of the sphere\n",
    "\n",
    "# spharms = []\n",
    "# for l in range(L_max+1):\n",
    "#     spharms.append(e3nn.o3.spherical_harmonics(l=l, x=vectors, normalize=True))\n",
    "# spharms = torch.cat(spharms, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X, Y, Z = torch.meshgrid(\n",
    "        torch.linspace(-1, 1, resolution),\n",
    "        torch.linspace(-1, 1, resolution),\n",
    "        torch.linspace(-1, 1, resolution)\n",
    "    )\n",
    "\n",
    "    versors = torch.stack([X, Y, Z], dim=-1)\n",
    "    spharms = []\n",
    "    for l in range(L_max+1):\n",
    "        spharms.append(e3nn.o3.spherical_harmonics(l=l, x=versors, normalize=True))\n",
    "    spharms = torch.cat(spharms, dim=-1)\n",
    "\n",
    "    vectors = r_max * versors\n",
    "    norms = torch.norm(vectors, dim=-1)\n",
    "\n",
    "    signal = torch.einsum('...i,ji,...j->...', basis(norms), weights, spharms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = 10\n",
    "# go.Figure([go.Surface(\n",
    "#     x=vectors[..., 0].numpy(),\n",
    "#     y=vectors[..., 1].numpy(),\n",
    "#     z=vectors[..., 2].numpy(),\n",
    "#     surfacecolor=signal[j].abs(),\n",
    "# )])\n",
    "\n",
    "# go.Figure([go.Surface(\n",
    "#     x=signal[j].abs()*vectors[..., 0].numpy(),\n",
    "#     y=signal[j].abs()*vectors[..., 1].numpy(),\n",
    "#     z=signal[j].abs()*vectors[..., 2].numpy(),\n",
    "#     surfacecolor=signal[j].abs(),\n",
    "# )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Volume(\n",
    "    x=vectors[..., 0].flatten(),\n",
    "    y=vectors[..., 1].flatten(),\n",
    "    z=vectors[..., 2].flatten(),\n",
    "    value=signal.flatten(),\n",
    "    isomin=-5.,\n",
    "    isomax=5.,\n",
    "    opacity=0.5, # needs to be small to see through all surfaces\n",
    "    surface_count=30, # needs to be a large number for good volume rendering\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heqbm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
